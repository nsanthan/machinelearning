<!DOCTYPE html>
<html lang="en">
<head>
  <title> EE 445 | Learning Outcomes </title>
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <meta charset="utf-8">

  <link rel="stylesheet" href="/ee445/css/themes/spacelab/bootstrap.min.css">
  <link rel="stylesheet" href="/ee445/css/style.css">
  <link rel="stylesheet" href="/ee445/css/syntax.css">
  <link rel="shortcut icon" href="/ee445/favicon.ico" type="image/x-icon" />
  <script src="https://kit.fontawesome.com/020726ec0d.js" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/anchor-js/anchor.min.js"></script>

  

  <!-- Load JQuery, then use it to attach the class 'active' to navbar item currently displayed. -->
  <script src="https://code.jquery.com/jquery-3.6.0.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script>
  <script>
    $(window).on('load', function () {
      $('.nav-item').find('a[href="' + location.pathname + '"]').addClass('active');
    });
  </script>

</head>
<body>

<div class="navbar navbar-expand-lg fixed-top navbar-light bg-light">
  <div class="container">
    <a class="navbar-brand" href="/ee445/index.html"> EE 445 </a>
    <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarResponsive" aria-controls="navbarResponsive" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>
    <div class="collapse navbar-collapse" id="navbarResponsive">
      <ul class="navbar-nav">
        
        <li class="nav-item"><a class="nav-link" href="/ee445/prerequisites/">Prerequisites</a></li>
        
        <li class="nav-item"><a class="nav-link" href="/ee445/modules/">Modules</a></li>
        
        <li class="nav-item"><a class="nav-link" href="/ee445/outcomes/">Outcomes</a></li>
        
        
        <li class="nav-item"><a class="nav-link" href="/ee445/readings/">Readings</a></li>
        
        
        <li class="nav-item"><a class="nav-link" href="/ee445/experiences/">Experiences</a></li>
        
        
        <li class="nav-item"><a class="nav-link" href="/ee445/assessments/">Assessments</a></li>
        
        
        <li class="nav-item"><a class="nav-link" href="/ee445/schedule/">Schedule</a></li>
        
      </ul>
    </div>
  </div>
</div>


<!-- Internal fragment for displaying the breadcrumb bar -->
<div class="breadcrumb-background" style="padding-top: 1em; padding-bottom: .01em">
  <div class="container">
    <nav aria-label="breadcrumb">
      <ol class="breadcrumb">
        
        <li class="breadcrumb-item"><a href="/ee445/">Home</a></li>
        <li class="breadcrumb-item active">Learning Outcomes</li>
      </ol>
    </nav>
  </div>
</div>

<div class="container">
  <h1>Learning Outcomes <small class="header-small">What you will know</small></h1>
</div>

<div class="container">
  <p>This page collects together all of the “outcomes” associated with individual modules. Outcomes identify what students will know and be able to do if they master the material.</p>

<h3 id="course-level-outcomes">Course-level outcomes</h3>

<p>Students mastering the material in this course will achieve the following student learning outcomes for the ICS undergraduate degree program:</p>

<ul>
  <li>[A] Students can apply knowledge of computing and mathematics appropriate to the discipline.</li>
  <li>[B] Students can analyze a problem, and identify and define the computing requirements appropriate to its solution.</li>
  <li>[C] Students can design, implement, and evaluate a computer-based system, process, component, or program to meet desired needs.</li>
</ul>


</div>

<div class="section-background-1">
  <div class="container">
    <a href="#" style="padding-top: 50px; margin-top: -50px; display: table-caption;" id="outcome-course-structure"></a><h3>Take aways from EE 445</h3>
    <p>
      
    </p>
    <ul>
  <li>You understand the basic building blocks of machine learning</li>
  <li>You understand every module at level covered in class</li>
  <li>You can handle datasets, implement the material learned in class using libraries or your own code</li>
  <li>You understand the connections between concepts here and in other courses you have learned</li>
  <li>You have the ability to follow the advanced material in modules with some help from me</li>
  <li>You have a good picture of the diversity of applications from the modules</li>
</ul>

    <p>
    <em>Referencing modules:</em>
    
      <a href="../modules/example-introduction">Introduction to Machine Learning</a>
    
    </p>
    

  </div>
</div>

<div class="section-background-2">
  <div class="container">
    <a href="#" style="padding-top: 50px; margin-top: -50px; display: table-caption;" id="outcome-gaussians-1"></a><h3>Competent with basics of univariate and multivariate Gaussians</h3>
    <p>
      
    </p>
    <ul>
  <li>You understand how to use and operate univariate Gaussians, including certain definite integrals involved in moment calculations</li>
  <li>You understand what jointly Gaussian random variables are, and can give an example of two Gaussians that are \emph{not} multivariate Gaussian</li>
  <li>You understand how to find the conditional expectations with multivariate Gaussian random variables</li>
</ul>

    <p>
    <em>Referencing modules:</em>
    
      <a href="../modules/gaussians">Gaussians</a>
    
    </p>
    

  </div>
</div>

<div class="section-background-1">
  <div class="container">
    <a href="#" style="padding-top: 50px; margin-top: -50px; display: table-caption;" id="outcome-lc"></a><h3>Linear Classifiers</h3>
    <p>
      
    </p>
    <ul>
  <li>Recognize different fundamental approaches to Linear Classification</li>
  <li>Understand how to formulate the Fisher Discriminant (not necessary for Spr 23)</li>
  <li>Understand the maximum entropy principle, Logistic Regression as an example</li>
  <li>Understand the margin approach, Support Vector Machine as an example</li>
</ul>


    <p>
    <em>Referencing modules:</em>
    
      <a href="../modules/module-linclass">Linear Classifiers</a>
    
    </p>
    

  </div>
</div>

<div class="section-background-2">
  <div class="container">
    <a href="#" style="padding-top: 50px; margin-top: -50px; display: table-caption;" id="outcome-nn"></a><h3>Neural Networks</h3>
    <p>
      
    </p>
    <ul>
  <li>You are able to build simple neural networks (feedforward/autoencoders)</li>
  <li>You are familiar with multivariate Taylor series, the gradient and the Hessian (see background if not)</li>
  <li>You understand (at a high level) stochastic gradient descent, and its accelerations to replicate some second order behavior using past values of gradients</li>
  <li>You can train networks using stochastic gradient descent/variants</li>
  <li>You understand autoencoder architectures (linear activations) in relation to the singular value decomposition</li>
  <li>You can train autoencoders to project training datasets to low dimensional (potentially non-linear) manifolds</li>
</ul>


    <p>
    <em>Referencing modules:</em>
    
      <a href="../modules/module-nn">Neural networks</a>
    
    </p>
    

  </div>
</div>

<div class="section-background-1">
  <div class="container">
    <a href="#" style="padding-top: 50px; margin-top: -50px; display: table-caption;" id="outcome-perceptron"></a><h3>Single Neuron Networks</h3>
    <p>
      
    </p>
    <ul>
  <li>Build and train a neuron on keras/tensorflow using stochastic gradient descent</li>
  <li>Form an initial idea of Stochastic Gradient Descent using the example of Perceptron Learning Algorithm</li>
  <li>Understand how the choice of activation/loss and regularization can replicate well known machine learning algorithsm</li>
</ul>

    <p>
    <em>Referencing modules:</em>
    
      <a href="../modules/module-snn">Single neuron networks</a>
    
    </p>
    

  </div>
</div>

<div class="section-background-2">
  <div class="container">
    <a href="#" style="padding-top: 50px; margin-top: -50px; display: table-caption;" id="outcome-lr"></a><h3>Linear Regression</h3>
    <p>
      
    </p>
    <ul>
  <li>Formulate linear least squares from Maximum Likelihood and Bayesian perspectives</li>
  <li>Understand Bayesian linear least squares and ridge regression</li>
  <li>Connect Ridge Regression with conditional means of multivariate Gaussians</li>
  <li>Appreciate the distinction between geometry of regression and generalization</li>
  <li>Some idea of significance of features ((t-)statistics)</li>
  <li>Feature selection using LASSO</li>
</ul>


    <p>
    <em>Referencing modules:</em>
    
      <a href="../modules/module-lr">Linear Regression</a>
    
    </p>
    

  </div>
</div>

<div class="section-background-1">
  <div class="container">
    <a href="#" style="padding-top: 50px; margin-top: -50px; display: table-caption;" id="outcome-conjunctions"></a><h3>Outcomes</h3>
    <p>
      
    </p>
    <ul>
  <li>Understand the purpose behind this formulation.</li>
  <li>You should be able to set up a learning problem in the standard
probabilistic framework (which we will call Probably Approximately
Correct or PAC learning), specifically the notions of
\emph{confidence} and \emph{accuracy}.</li>
  <li>For the problem of learning conjunctions, you should
understand how to derive the PAC bound on the training sample, and
be able to work out similar bounds for simple problems.</li>
</ul>


    <p>
    <em>Referencing modules:</em>
    
      <a href="../modules/module-learning-conjunctions">Learning conjunctions in a PAC framework</a>
    
    </p>
    

  </div>
</div>

<div class="section-background-2">
  <div class="container">
    <a href="#" style="padding-top: 50px; margin-top: -50px; display: table-caption;" id="outcome-svm"></a><h3>Single Neuron Networks</h3>
    <p>
      
    </p>
    <ul>
  <li>Understand how to set up the maximum margin classifier in the linearly separable case</li>
  <li>Extend the linear separable case to non-linearly separable data</li>
  <li>Understand the convex optimization setup, Lagrangians and the dual formulation</li>
  <li>Appreciate the nature of solutions of the SVM:
    <ul>
      <li>only certain examples (support vectors) determine the solution, identify these from Lagrange multipliers</li>
      <li>Appreciate that the SVM formulation only deals with pairwise dot products among examples</li>
    </ul>
  </li>
  <li>Kernel trick that allows us to move from linear to non-linear classification boundaries in the example space</li>
</ul>

    <p>
    <em>Referencing modules:</em>
    
      <a href="../modules/module-svm">Support vector machines</a>
    
    </p>
    

  </div>
</div>






<!-- Maybe find a different way?
<script src="/ee445/js/scrollIfAnchor.js"></script>
-->

<footer class="footer footer-background" style="padding-top: 1em; padding-bottom: 1em">
  <div class="container text-center">
    
    <p>Narayana Prasad Santhanam | Electrical and Computer Engineering | University of Hawaii <br />
nsanthan@hawaii.edu<br /></p>


    
    <p style="margin: 0">Powered by the <a class="footer-link" href="https://morea-framework.github.io/">Morea Framework</a> (Theme: spacelab)<br>
      Last update on: <span>2023-05-02 23:36:31 -1000</span></p>

    <p style="margin: 0">
      
      1 prerequisites |
      
      8 modules
      
      | 11 outcomes
      
      
      | 35 readings
      
      
      | 28 experiences
      
      
      | 9 assessments
      
    </p>
  </div>
</footer>


<!-- Load Bootstrap JavaScript components -->
<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.0.2/dist/js/bootstrap.bundle.min.js" integrity="sha384-MrcW6ZMFYlzcLA8Nl+NtUVF0sA7MsXsP1UyJoMp4YLEuNSfAP+JcXn/tWtIaxVXM" crossorigin="anonymous"></script>


<script type="text/javascript" async
        src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-MML-AM_CHTML">
</script>


<!-- Add anchors to pages. -->
<script>anchors.add();</script>


</body>
</html>
